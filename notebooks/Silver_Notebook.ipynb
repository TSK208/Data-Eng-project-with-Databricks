{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6d504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the task value from the previous task (bronze)\n",
    "bronze_output = dbutils.jobs.taskValues.get(taskKey=\"Bronze\", key=\"bronze_output\")\n",
    "\n",
    "# Access individual variables\n",
    "start_date = bronze_output.get(\"start_date\", \"\")\n",
    "bronze_adls = bronze_output.get(\"bronze_adls\", \"\")\n",
    "silver_adls = bronze_output.get(\"silver_adls\", \"\")\n",
    "\n",
    "print(f\"Start Date: {start_date}, Bronze ADLS: {bronze_adls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72b8b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, isnull, when\n",
    "from pyspark.sql.types import TimestampType\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccbdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data into a Spark DataFrame\n",
    "df = spark.read.option(\"multiline\", \"true\").json(f\"{bronze_adls}{start_date}_earthquake_data.json\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape earthquake data\n",
    "df = (\n",
    "    df\n",
    "    .select(\n",
    "        'id',\n",
    "        col('geometry.coordinates').getItem(0).alias('longitude'),\n",
    "        col('geometry.coordinates').getItem(1).alias('latitude'),\n",
    "        col('geometry.coordinates').getItem(2).alias('elevation'),\n",
    "        col('properties.title').alias('title'),\n",
    "        col('properties.place').alias('place_description'),\n",
    "        col('properties.sig').alias('sig'),\n",
    "        col('properties.mag').alias('mag'),\n",
    "        col('properties.magType').alias('magType'),\n",
    "        col('properties.time').alias('time'),\n",
    "        col('properties.updated').alias('updated')\n",
    "    )\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348da4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data: Check for missing or null values\n",
    "df = (\n",
    "    df\n",
    "    .withColumn('longitude', when(isnull(col('longitude')), 0).otherwise(col('longitude')))\n",
    "    .withColumn('latitude', when(isnull(col('latitude')), 0).otherwise(col('latitude')))\n",
    "    .withColumn('time', when(isnull(col('time')), 0).otherwise(col('time')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87953c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' and 'updated' to timestamp from Unix time\n",
    "df = (\n",
    "    df\n",
    "    .withColumn('time', (col('time') / 1000).cast(TimestampType()))\n",
    "    .withColumn('updated', (col('updated') / 1000).cast(TimestampType()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e96db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the transformed DataFrame to the Silver container\n",
    "silver_output_path = f\"{silver_adls}earthquake_events_silver/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587312d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
